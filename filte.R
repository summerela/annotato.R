#!/usr/bin/env Rscript
############################################################################################
###############################   filte.R     ############################################## 
##  PURPOSE: This program takes as input a fasta file, FPKM generated by RSEM, and a blast
##           report in tabular format (outfmt 6) and runs the fasta file through filtering
##           parameters, merging the results using CD-HIT-EST.  
##  Output:
##      transPS.fa = fasta file of merged .scaffold and .accept TransPS results files
##      man_filtered.fa = manually filtered fasta file
##      final_merged.fa = final merged fasta file of all filtering methods after
##                        removing redundancy with cd-hit-est
##      final_merged.fa_blastx = blast report of final filtered fasta file
##      filter_stats.pdf = pdf graph of filtering results
###############################################################################################
options(error=traceback)
########################
## Loading libraries  ##
########################
#create list of required pacakges
packages <- c("CHNOSZ", "Biostrings", "parallel", "data.table")
##load packages
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())),repos="http://cran.r-project.org")
}
##load packages
suppressPackageStartupMessages(lapply(packages, require, character.only=T))

##########################
## Read in config file  ##
##########################
source("user_config.R")
source("script_config.R")
source("program_config.R")

##check that output directory exists
dir.create(file.path(output_dir))

##create base_files directory
dir.create(file.path(paste(output_dir, "filtering", sep="/")))
filtered_output <- paste(output_dir, "filtering", sep="/")

##change working directory to output directory
setwd(filtered_output)

######################
## Detonate command ##
######################
##Estimate reference transcript distribution
system(paste(detonate_dist, ref.fa, paste(basename(ref.fa), "reference", sep="_"), sep=" "), wait=TRUE)

##Calculate RSEM-eval score
##paired 
if (reads == "paired" | reads == "PAIRED"){
    if (direction == 0){
        det_cmd <- paste(detonate, "-p", CPU, "--bowtie-chunkmbs 200 --samtools-sort-mem 10G --forward-prob 1 --transcript-length-parameters", paste(filtered_output, paste(basename(ref.fa), "reference", sep="_"), sep="/"), "--paired-end", left, right, final.fa, paste(basename(final.fa), "DetScore", sep="_"), avg_ins)
    }
    if (direction == 1){
        det_cmd <- paste(detonate, "-p", CPU, "--bowtie-chunkmbs 200 --samtools-sort-mem 10G --forward-prob 0 --transcript-length-parameters", paste(filtered_output, paste(basename(ref.fa), "reference", sep="_"), sep="/"), "--paired-end", left, right, final.fa, paste(basename(final.fa), "DetScore", sep="_"), avg_ins)
    }
     if (direction == 2){
        det_cmd <- paste(detonate, "-p", CPU, "--bowtie-chunkmbs 200 --samtools-sort-mem 10G --transcript-length-parameters", paste(filtered_output, paste(basename(ref.fa), "reference", sep="_"), sep="/"), "--paired-end", left, right, final.fa, paste(basename(final.fa), "DetScore", sep="_"), avg_ins)
    }
}

##single-end 
if (reads == "single" | reads == "SINGLE"){
    if (direction == 0){
        det_cmd <- paste(detonate, "-p", CPU, "--bowtie-chunkmbs 200 --samtools-sort-mem 10G --forward-prob 1 --transcript-length-parameters", paste(filtered_output, paste(basename(ref.fa), "reference", sep="_"), sep="/"), "--paired-end", single, final.fa, paste(basename(final.fa), "DetScore", sep="_"), avg_ins)
    }
    if (direction == 1){
        det_cmd <- paste(detonate, "-p", CPU, "--bowtie-chunkmbs 200 --samtools-sort-mem 10G --forward-prob 0 --transcript-length-parameters", paste(filtered_output, paste(basename(ref.fa), "reference", sep="_"), sep="/"), "--paired-end", single, final.fa, paste(basename(final.fa), "DetScore", sep="_"), avg_ins)
    }
     if (direction == 2){
        det_cmd <- paste(detonate, "-p", CPU, "--bowtie-chunkmbs 200 --samtools-sort-mem 10G --transcript-length-parameters", paste(filtered_output, paste(basename(ref.fa), "reference", sep="_"), sep="/"), "--paired-end", single, final.fa, paste(basename(final.fa), "DetScore", sep="_"), avg_ins)
    }
}

##run detonate
cat("\n \n Running detonate...\n \n")
system(paste(det_cmd), wait=TRUE)

##################
## Run transPS  ##
##################
cat("\n Running TransPS..\n \n")
system(paste(transPS, "-t", final.fa, "-b", blastx_chick, "--evalue .01 --dist 100", sep=" "))

##find TransPS accepted and scaffolded contigs
trans_files <- list.files(dirname(final.fa), pattern="*.accept|*.scaffold")

##merge transPS accepted and scaffolded results
system(paste("cat", paste(paste(dirname(final.fa), trans_files, sep="/"), collapse=" "), ">", paste(filtered_output, "transPS.fa", sep="/")))

##set variable to call merged TransPS output
transPS.fa <- readDNAStringSet(paste(filtered_output, "transPS.fa", sep="/"))

##create variable for TransPS contigs that need further filtering 
unused <- readDNAStringSet(list.files(dirname(final.fa), pattern="*.unused", full.names=TRUE))
unused.df <- data.frame(comp=as.character(mclapply(strsplit(as.character(names(unused)), "@"), function(x) x[1], mc.cores=5)), seq=as.character(unused), length=width(unused))

##########################
## Run manual filtering ##
##########################
cat(paste("\n Manually filtering...\n"))
##isoform level filtering
if (filter_method == "isoform" | filter_method == "ISOFORM"){
    ##read in isoform counts
    FPKM.file <- data.table(read.table(isoforms_FPKM, header=TRUE, sep="\t"), key="transcript_id")
    ##Examine distribution of expressed transcripts
    system(paste(countFPKM, isoforms_FPKM, "> cumul_counts.txt"))    
    #filter just unused TransPS contigs
    FPKM.file <- FPKM.file[match(unused.df$comp, FPKM.file$transcript_id),]
    ##keep only genes with FPKM > 0
    fpkm <- FPKM.file[which(FPKM.file$FPKM >= 1),]
    ##read in blast report with eval >=.01 and PID>=30%
    blast <- data.table(read.blast(blastx_report, similarity=.30, evalue=.01, max.hits=1), key="queryId")
    ##read in impact score report
    impact <- read.table(paste(paste(basename(final.fa),
                                     "DetScore.score.isoforms.results", sep="_")),header=TRUE)
    ##kexep only contigs with impact score > 0
    impact <- impact[which(impact$contig_impact_score >= 0),]
    ##merge fpkm and det_score with blast; keep reads > 1 FPKM | blast evalue < .01 | impact >= 0    
    blast$transcript_id <- as.character(blast$queryId)
    fpkm$transcript_id <- as.character(fpkm$transcript_id)
    man.filtered <- merge(fpkm, blast, by="transcript_id", all.x=TRUE)
    man.filtered <- merge(man.filtered, impact, by="transcript_id", all.x=TRUE)
    ##save man.filtered FPKM file
    write.table(man.filtered, file=paste(filtered_output, "filteredFPKM.txt", sep="/"), quote=FALSE, sep="\t")
    ##calculate stats for filtered set
    write.table(man.filtered[,1:8, with = FALSE], file =paste(filtered_output,"filteredFPKM_counts.txt", sep="/"),
                quote=FALSE, sep="\t")
    ##Examine distribution of expressed filtered transcripts
    system(paste(countFPKM, paste(filtered_output,"filteredFPKM_counts.txt", sep="/"), "> filtered_counts.txt"))   
    ##plot fpkm distribution before and after filtering 
    pdf(paste(filtered_output, "isoform_counts.pdf", sep="/"))
    par(mfrow=c(2,1))
    before <- read.table(paste(filtered_output, "cumul_counts.txt", sep="/"), header=T)
    plot(before, xlab='-1*minFPKM', ylab='Isofom Count', type='b', main='Pre-filtering Isoform Count vs. minFPKM')
    after <- read.table(paste(filtered_output, "filtered_counts.txt", sep="/"), header=T)
    plot(after, xlab='-1*minFPKM', ylab='Isofom Count', type='b', main='Post-filtering Isoform Count vs. minFPKM')
    dev.off()
}

##collapse by gene level and filter
if (filter_method == "gene" | filter_method == "GENE"){
    ##read in isoform counts
    FPKM.file <- data.table(read.table(genes_FPKM, header=TRUE, sep="\t"), key="transcript_id")
    ##Examine distribution of expressed transcripts
    system(paste(countFPKM, genes_FPKM, "> cumul_counts.txt"))    
    ##keep only genes with FPKM > 0
    fpkm <- FPKM.file[which(FPKM.file$FPKM >= 1),]
    ##read in blast report with eval >=.01 and PID>=30%
    blast <- data.table(read.blast(blastx_report, similarity=.30, evalue=.01, max.hits=1), key="queryId")
    ##read in impact score report
    impact <- read.table(paste(paste(basename(final.fa),
                                     "DetScore.score.genesx.results", sep="_")),header=TRUE)
    ##keep only contigs with impact score > 0
    impact <- impact[which(impact$contig_impact_score >= 0),]
    ##merge fpkm and det_score with blast; keep reads > 1 FPKM | blast evalue < .01 | impact >= 0    
    blast$transcript_id <- as.character(blast$queryId)
    fpkm$transcript_id <- as.character(fpkm$transcript_id)
    man.filtered <- merge(fpkm, blast, by="transcript_id", all.x=TRUE)
    man.filtered <- merge(man.filtered, impact, by="transcript_id", all.x=TRUE)
    ##save man.filtered FPKM file
    write.table(man.filtered, file=paste(filtered_output, "filteredFPKM.txt", sep="/"), quote=FALSE, sep="\t")
    ##calculate stats for filtered set
    write.table(man.filtered[,1:8, with = FALSE], file =paste(filtered_output,"filteredFPKM_counts.txt", sep="/"),
                quote=FALSE, sep="\t")
    ##Examine distribution of expressed filtered transcripts
    system(paste(countFPKM, paste(filtered_output,"filteredFPKM_counts.txt", sep="/"), "> filtered_counts.txt"))   
    ##plot fpkm distribution before and after filtering 
    pdf(paste(filtered_output, "isoform_counts.pdf", sep="/"))
    par(mfrow=c(2,1))
    before <- read.table(paste(filtered_output, "cumul_counts.txt", sep="/"), header=T)
    plot(before, xlab='-1*minFPKM', ylab='Isofom Count', type='b', main='Pre-filtering Isoform Count vs. minFPKM')
    after <- read.table(paste(filtered_output, "filtered_counts.txt", sep="/"), header=T)
    plot(after, xlab='-1*minFPKM', ylab='Isofom Count', type='b', main='Post-filtering Isoform Count vs. minFPKM')
    dev.off()
}

#########################
## Gettting sequences  ##
#########################
cat("\n \n Generating a fasta file... \n \n")
##read in fasta file
og.fasta <- readDNAStringSet(final.fa)

##edit fasta names to match with blast report
names(og.fasta) <- mclapply(strsplit(as.character(names(og.fasta)), " "), function(x) x[1], mc.cores=5)

##get sequences for filtered data set
man.filtered$seq <- as.character(og.fasta)[match(as.character(man.filtered$transcript_id), as.character(names(og.fasta)))]

##convert to fasta file and save
man.filtered.fa <- DNAStringSet(man.filtered$seq)
names(man.filtered.fa) <- as.character(man.filtered$transcript_id)
writeXStringSet(man.filtered.fa, filepath=paste(filtered_output, "man_filtered.fa", sep="/"))

###############################################
## Merge filtered assemblies with CD-HIT-EST ##
###############################################
cat("\n Merging filtered fasta files...\n")
##combine TransPS.fa and manually filtered fasta
system(paste("cat", paste(filtered_output, "transPS.fa", sep="/"), paste(filtered_output, "man_filtered.fa", sep="/"), ">", paste(filtered_output, "filtering_merged.fa", sep="/"), sep=" "))

##run cd-hit-est on merged fasta file
cat(paste("\n \n Removing redundancy... \n \n"))
system(paste(cd.hit.est, "-T", CPU, "-i", paste(filtered_output, "filtering_merged.fa", sep="/"), "-c 0.99 -o", paste(filtered_output, "final_merged.fa", sep="/"), sep=" "))

##read file in for stats
final.filtered <- readDNAStringSet(paste(filtered_output, "final_merged.fa", sep="/"))

############################################
## Clean up merged fasta headers & blast  ##
############################################
##clean up headers
names(final.filtered) <- mclapply(strsplit(as.character(names(final.filtered)), "&|@"), function(x) x[1], mc.cores=5)
##write to a file
writeXStringSet(final.filtered, filepath=paste(filtered_output, "final_merged.fa", sep="/"))
##blast filtered results
system(paste("blastx -db", blastdb, "-query", paste(filtered_output, "final_merged.fa", sep="/"), "-evalue .01 -max_target_seqs 1 -outfmt 6 -num_threads", CPU, "-out",  paste(filtered_output, "final_merged.fa_blastx", sep="/")))

#################################
##  Calculate filtering stats ###
#################################
cat("\n Calculating filtering stats... \n \n")

##calc number of transcripts in each method
og.count <- length(og.fasta)
transPS.count <- length(transPS.fa)
man.count <- length(man.filtered.fa)
final.count <- length(final.filtered)

##calc % of transcripts in each method
og.kept <- og.count/og.count * 100
transPS.kept <- transPS.count/og.count * 100
man.kept <- man.count/og.count * 100
final.kept <- final.count/og.count * 100

##merge data into a data frame for graphing
counts <- data.frame(kept=rbind(og.count, transPS.count, man.count, final.count))
rownames(counts) <- c("Original Assembly", "transPS", "Manual Filter", "Final Filtered")

#############################
## Graph filtering stats  ###
#############################
cat("\n Making a graph...\n")
##barplot of reads and transcripts kept after filtering
pdf("filter_stats.pdf")
bplt <- barplot(counts$kept, beside=TRUE, names=rownames(counts), main="Number of Kept Contigs", col=c("green", "pink", "light blue", "violet"), ylab="# Comps Kept")
text(bplt, counts$kept-5, labels=paste(format(((counts$kept/og.count)*100), digits=2), "%", sep=""), col="black",cex=1.25)
dev.off()

##let everyone know it's finished
cat("Filtering complete: final output written to final_merged.fa", "\n")




